# ğŸ¤– RAG + GPT Integration Flow

## ğŸ¯ Má»¥c Ä‘Ã­ch

Káº¿t há»£p **RAG (Retrieval-Augmented Generation)** vá»›i **Google AI (Gemini)** Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn **dá»¯ liá»‡u thá»±c táº¿** tá»« hÃ³a Ä‘Æ¡n Ä‘Ã£ upload.

## ğŸ“Š Workflow Chi Tiáº¿t

### 1ï¸âƒ£ User há»i cÃ¢u há»i

```
User: "CÃ³ bao nhiÃªu hÃ³a Ä‘Æ¡n cá»§a CÃ”NG TY ABC?"
```

### 2ï¸âƒ£ Chatbot detect intent

```python
Intent: data_query
Pattern matched: r'(cÃ³ bao nhiÃªu|bao nhiÃªu)'
Handler: handle_data_query()
```

### 3ï¸âƒ£ RAG Semantic Search

```http
POST http://localhost:8000/chat/rag-search
Content-Type: application/json

{
  "query": "CÃ³ bao nhiÃªu hÃ³a Ä‘Æ¡n cá»§a CÃ”NG TY ABC?",
  "top_k": 5
}
```

**RAG Service:**

- Embed query thÃ nh vector (sentence-transformers)
- Search trong ChromaDB
- TÃ¬m top 5 documents tÆ°Æ¡ng tá»± nháº¥t
- Return vá»›i score + metadata

**Response:**

```json
{
  "success": true,
  "results": [
    {
      "content": "Invoice: MTT-001\nBuyer: CÃ”NG TY ABC\nAmount: 1,500,000 VND",
      "score": 0.95,
      "metadata": {
        "invoice_code": "MTT-001",
        "buyer_name": "CÃ”NG TY ABC",
        "total_amount": "1,500,000 VND"
      }
    },
    {
      "content": "Invoice: MTT-003\nBuyer: CÃ”NG TY ABC\nAmount: 2,300,000 VND",
      "score": 0.88,
      "metadata": {
        "invoice_code": "MTT-003",
        "buyer_name": "CÃ”NG TY ABC",
        "total_amount": "2,300,000 VND"
      }
    }
  ]
}
```

### 4ï¸âƒ£ Chuáº©n bá»‹ Context cho GPT

```python
rag_context = """THÃ”NG TIN Tá»ª Há»† THá»NG:

TÃ i liá»‡u 1 (Ä‘á»™ phÃ¹ há»£p: 0.95):
Invoice: MTT-001
Buyer: CÃ”NG TY ABC
Seller: CÃ”NG TY ÄIá»†N Lá»°C
Amount: 1,500,000 VND
Type: HÃ³a Ä‘Æ¡n tiá»n Ä‘iá»‡n
MÃ£ hÃ³a Ä‘Æ¡n: MTT-001
KhÃ¡ch hÃ ng: CÃ”NG TY ABC
Tá»•ng tiá»n: 1,500,000 VND

---

TÃ i liá»‡u 2 (Ä‘á»™ phÃ¹ há»£p: 0.88):
Invoice: MTT-003
Buyer: CÃ”NG TY ABC
Seller: CÃ”NG TY NÆ¯á»šC Sáº CH
Amount: 2,300,000 VND
Type: HÃ³a Ä‘Æ¡n tiá»n nÆ°á»›c
MÃ£ hÃ³a Ä‘Æ¡n: MTT-003
KhÃ¡ch hÃ ng: CÃ”NG TY ABC
Tá»•ng tiá»n: 2,300,000 VND

---
"""
```

### 5ï¸âƒ£ Táº¡o Prompt cho Google AI

```python
prompt = f"""Báº¡n lÃ  trá»£ lÃ½ AI thÃ´ng minh. Dá»±a trÃªn thÃ´ng tin dÆ°á»›i Ä‘Ã¢y, hÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  chi tiáº¿t.

{rag_context}

CÃ‚U Há»I: CÃ³ bao nhiÃªu hÃ³a Ä‘Æ¡n cá»§a CÃ”NG TY ABC?

HÃ£y tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ á»Ÿ trÃªn. Náº¿u cÃ³ nhiá»u hÃ³a Ä‘Æ¡n, hÃ£y liá»‡t kÃª rÃµ rÃ ng. Sá»­ dá»¥ng emoji vÃ  format markdown Ä‘á»ƒ dá»… Ä‘á»c."""
```

### 6ï¸âƒ£ Google AI phÃ¢n tÃ­ch & tráº£ lá»i

**Google AI (Gemini-Pro) response:**

```markdown
ğŸ“Š **Káº¿t quáº£ tÃ¬m kiáº¿m cho CÃ”NG TY ABC:**

Há»‡ thá»‘ng tÃ¬m tháº¥y **2 hÃ³a Ä‘Æ¡n** cá»§a CÃ”NG TY ABC:

**1. HÃ³a Ä‘Æ¡n tiá»n Ä‘iá»‡n (MTT-001)**
â€¢ NhÃ  cung cáº¥p: CÃ”NG TY ÄIá»†N Lá»°C
â€¢ Sá»‘ tiá»n: 1,500,000 VND
â€¢ Äá»™ phÃ¹ há»£p: 95%

**2. HÃ³a Ä‘Æ¡n tiá»n nÆ°á»›c (MTT-003)**
â€¢ NhÃ  cung cáº¥p: CÃ”NG TY NÆ¯á»šC Sáº CH
â€¢ Sá»‘ tiá»n: 2,300,000 VND
â€¢ Äá»™ phÃ¹ há»£p: 88%

ğŸ’° **Tá»•ng chi phÃ­:** 3,800,000 VND

ğŸ“ˆ **PhÃ¢n tÃ­ch:**
CÃ”NG TY ABC cÃ³ 2 loáº¡i chi phÃ­ dá»‹ch vá»¥ cÃ´ng cá»™ng:

- Tiá»n Ä‘iá»‡n: 1.5 triá»‡u (39%)
- Tiá»n nÆ°á»›c: 2.3 triá»‡u (61%)

ğŸ’¡ **Gá»£i Ã½:** Báº¡n cÃ³ thá»ƒ há»i thÃªm vá» chi tiáº¿t tá»«ng hÃ³a Ä‘Æ¡n hoáº·c upload thÃªm hÃ³a Ä‘Æ¡n má»›i!
```

### 7ï¸âƒ£ Chatbot tráº£ vá» User

```json
{
  "message": "ğŸ¤– **Tráº£ lá»i tá»« AI (dá»±a trÃªn 2 tÃ i liá»‡u):**\n\nğŸ“Š Káº¿t quáº£ tÃ¬m kiáº¿m...",
  "type": "ai_rag_response",
  "data": [...],
  "suggestions": [
    "Há»i thÃªm",
    "Xem chi tiáº¿t",
    "Upload thÃªm",
    "Thá»‘ng kÃª"
  ]
}
```

## ğŸ”‘ Key Components

### 1. RAG Service (`rag_service.py`)

```python
def search_similar_documents(query: str, top_k: int = 5):
    """
    Semantic search in vector database
    - Embed query vá»›i sentence-transformers
    - Search trong ChromaDB
    - Return top_k results vá»›i scores
    """
```

### 2. Google AI Service (`google_ai_service.py`)

```python
def generate_response(prompt: str) -> str:
    """
    Generate response tá»« Google AI
    - Input: Full prompt vá»›i RAG context
    - Model: gemini-pro
    - Output: Natural language response
    """
```

### 3. Chat Handler (`chat_handler.py`)

```python
def handle_data_query(message: str, context: Dict):
    """
    1. Call RAG search endpoint
    2. Get documents + metadata
    3. Build context tá»« RAG results
    4. Create prompt vá»›i context
    5. Call Google AI
    6. Return AI response
    """
```

## ğŸ’¡ VÃ­ dá»¥ thá»±c táº¿

### Example 1: Äáº¿m sá»‘ lÆ°á»£ng

**User:** "CÃ³ bao nhiÃªu hÃ³a Ä‘Æ¡n?"

**RAG Search:** TÃ¬m táº¥t cáº£ documents
**Result:** 5 documents

**GPT Prompt:**

```
THÃ”NG TIN: 5 tÃ i liá»‡u (MTT-001, MTT-002, MTT-003, MTT-004, MTT-005)
CÃ‚U Há»I: CÃ³ bao nhiÃªu hÃ³a Ä‘Æ¡n?
```

**AI Response:**

```
ğŸ“Š Há»‡ thá»‘ng cÃ³ **5 hÃ³a Ä‘Æ¡n**:
1. MTT-001 - CÃ”NG TY ABC
2. MTT-002 - CÃ”NG TY XYZ
...
```

### Example 2: TÃ¬m theo khÃ¡ch hÃ ng

**User:** "TÃ¬m hÃ³a Ä‘Æ¡n cá»§a CÃ”NG TY ABC"

**RAG Search:** Semantic search "CÃ”NG TY ABC"
**Result:** 2 documents (score: 0.95, 0.88)

**GPT Prompt:**

```
THÃ”NG TIN:
- MTT-001: CÃ”NG TY ABC, 1.5M
- MTT-003: CÃ”NG TY ABC, 2.3M
CÃ‚U Há»I: TÃ¬m hÃ³a Ä‘Æ¡n cá»§a CÃ”NG TY ABC
```

**AI Response:**

```
ğŸ” TÃ¬m tháº¥y 2 hÃ³a Ä‘Æ¡n cá»§a CÃ”NG TY ABC:
1. MTT-001: Äiá»‡n - 1.5M
2. MTT-003: NÆ°á»›c - 2.3M
Tá»•ng: 3.8M
```

### Example 3: So sÃ¡nh

**User:** "So sÃ¡nh chi phÃ­ Ä‘iá»‡n vÃ  nÆ°á»›c"

**RAG Search:** TÃ¬m documents liÃªn quan "Ä‘iá»‡n" vÃ  "nÆ°á»›c"
**Result:** 4 documents

**GPT Prompt:**

```
THÃ”NG TIN:
- MTT-001: Äiá»‡n, 1.5M
- MTT-002: NÆ°á»›c, 2.0M
- MTT-005: Äiá»‡n, 1.8M
- MTT-007: NÆ°á»›c, 2.2M
CÃ‚U Há»I: So sÃ¡nh chi phÃ­ Ä‘iá»‡n vÃ  nÆ°á»›c
```

**AI Response:**

```
ğŸ“Š So sÃ¡nh chi phÃ­:

ğŸ’¡ **Äiá»‡n:**
- Sá»‘ lÆ°á»£ng: 2 hÃ³a Ä‘Æ¡n
- Tá»•ng: 3.3M
- Trung bÃ¬nh: 1.65M

ğŸ’§ **NÆ°á»›c:**
- Sá»‘ lÆ°á»£ng: 2 hÃ³a Ä‘Æ¡n
- Tá»•ng: 4.2M
- Trung bÃ¬nh: 2.1M

ğŸ“ˆ Chi phÃ­ nÆ°á»›c cao hÆ¡n Ä‘iá»‡n 27%
```

## ğŸ¨ Response Format

### Success (cÃ³ Google AI):

```json
{
  "message": "ğŸ¤– **Tráº£ lá»i tá»« AI (dá»±a trÃªn N tÃ i liá»‡u):**\n\n[AI response]",
  "type": "ai_rag_response",
  "data": [...],
  "suggestions": [...]
}
```

### Fallback (khÃ´ng cÃ³ Google AI):

```json
{
  "message": "ğŸ” **TÃ¬m tháº¥y N káº¿t quáº£:**\n\n[Raw data list]",
  "type": "rag_search_results",
  "data": [...],
  "suggestions": [...]
}
```

## âš™ï¸ Configuration

### Environment Variables

```env
# Google AI
GOOGLE_AI_API_KEY=AIzaSyAatyIQf08xSSuBzR9u_Eb9uwPUbq3D0OA

# RAG
CHROMA_PERSIST_DIRECTORY=./chroma_db
SENTENCE_TRANSFORMERS_MODEL=all-MiniLM-L6-v2
```

### Dependencies

```txt
# Google AI
google-generativeai>=0.3.0

# RAG
sentence-transformers>=2.2.0
chromadb>=0.4.0
```

## ğŸ” Debugging

### Enable logging

```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

logger.info(f"RAG found {len(documents)} docs")
logger.info(f"Google AI response: {ai_response[:100]}...")
```

### Check RAG results

```python
print(f"RAG Results: {len(documents)}")
for doc in documents:
    print(f"- {doc['metadata']['invoice_code']}: {doc['score']:.2f}")
```

### Test Google AI

```python
if self.google_ai.is_available():
    test_prompt = "Hello, test response"
    response = self.google_ai.generate_response(test_prompt)
    print(f"Google AI working: {response}")
```

## ğŸš€ Performance

| Operation  | Time        | Notes               |
| ---------- | ----------- | ------------------- |
| RAG Search | ~0.2-0.5s   | Depends on DB size  |
| Google AI  | ~1-3s       | Network latency     |
| **Total**  | **~1.5-4s** | Acceptable for chat |

## ğŸ“ˆ Advantages

1. âœ… **Tráº£ lá»i dá»±a trÃªn data thá»±c:** KhÃ´ng hallucinate
2. âœ… **Semantic search:** Hiá»ƒu Ã½ nghÄ©a, khÃ´ng chá»‰ keyword
3. âœ… **Natural response:** GPT format Ä‘áº¹p, dá»… Ä‘á»c
4. âœ… **Context-aware:** GPT phÃ¢n tÃ­ch data thÃ´ng minh
5. âœ… **Scalable:** ThÃªm documents â†’ tá»± Ä‘á»™ng search Ä‘Æ°á»£c

## âš ï¸ Limitations

1. â±ï¸ **Latency:** Tá»•ng ~1.5-4s (RAG + GPT)
2. ğŸ’° **Cost:** Google AI API cÃ³ giá»›i háº¡n free tier
3. ğŸ”’ **Dependency:** Cáº§n internet cho Google AI
4. ğŸ“¦ **Model size:** sentence-transformers ~90MB

## ğŸ¯ Best Practices

1. **Limit context:** Chá»‰ gá»­i top 5 documents cho GPT
2. **Cache results:** Cache RAG results náº¿u query giá»‘ng nhau
3. **Fallback:** CÃ³ raw data display náº¿u GPT fail
4. **Error handling:** Graceful degradation náº¿u RAG/GPT down
5. **Prompt engineering:** Optimize prompt Ä‘á»ƒ GPT tráº£ lá»i tá»‘t hÆ¡n

---

**Version:** 3.0 (RAG + GPT Integration)
**Last Updated:** 2025-10-01
