"""
Rasa Chat Handler
Handler ch√≠nh ƒë·ªÉ giao ti·∫øp v·ªõi Rasa, v·ªõi fallback sang OpenAI khi c·∫ßn
"""

import requests
import json
import logging
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
from models.ai_model import AIModel

logger = logging.getLogger(__name__)

class RasaChatHandler:
    """
    Rasa-first chatbot handler
    
    Flow:
    1. Rasa x·ª≠ l√Ω tin nh·∫Øn tr∆∞·ªõc
    2. Ki·ªÉm tra ch·∫•t l∆∞·ª£ng response
    3. N·∫øu kh√¥ng t·ªët, fallback sang OpenAI v·ªõi context t·ª´ Rasa
    4. Tr·∫£ v·ªÅ response t·ªët nh·∫•t
    """
    
    def __init__(self):
        self.ai_model = AIModel()
        self.rasa_url = os.getenv('RASA_URL', 'http://rasa:5005')  # T·ª´ environment
        self.conversation_history = {}
        
        # Confidence thresholds - Stricter thresholds
        self.min_confidence = 0.5  # TƒÉng t·ª´ 0.3 ‚Üí 0.5 ƒë·ªÉ ch·∫∑t ch·∫Ω h∆°n
        self.good_confidence = 0.8  # TƒÉng t·ª´ 0.7 ‚Üí 0.8
        self.excellent_confidence = 0.9  # Threshold m·ªõi cho response xu·∫•t s·∫Øc
        
        # Enhanced response quality checks
        self.bad_response_patterns = [
            "xin l·ªói, t√¥i kh√¥ng hi·ªÉu",
            "t√¥i kh√¥ng bi·∫øt", 
            "t√¥i kh√¥ng th·ªÉ hi·ªÉu",
            "utter_default",
            "sorry, i didn't get that",
            "i don't understand",
            "could you please rephrase",
            "t√¥i c·∫ßn th√™m th√¥ng tin",
            "b·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n kh√¥ng",
            "t√¥i ch∆∞a ƒë∆∞·ª£c training",
            "h√£y h·ªèi theo c√°ch kh√°c"
        ]
        
        # Suspicious response patterns (c√≥ th·ªÉ l√† "b·ªãa")
        self.suspicious_patterns = [
            "theo t√¥i hi·ªÉu",
            "c√≥ l·∫Ω",
            "t√¥i nghƒ© r·∫±ng", 
            "d∆∞·ªùng nh∆∞",
            "c√≥ th·ªÉ",
            "th∆∞·ªùng th√¨",
            "trong tr∆∞·ªùng h·ª£p n√†y"
        ]
        
        # Generic/vague responses that should trigger fallback
        self.generic_patterns = [
            "c·∫£m ∆°n b·∫°n",
            "r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£",
            "t√¥i ·ªü ƒë√¢y ƒë·ªÉ gi√∫p",
            "b·∫°n c·∫ßn g√¨ kh√°c",
            "c√≥ g√¨ kh√°c t√¥i c√≥ th·ªÉ gi√∫p"
        ]
        
        # System prompts for OpenAI fallback
        self.system_prompts = {
            'invoice_context': """
B·∫°n l√† tr·ª£ l√Ω AI chuy√™n v·ªÅ h√≥a ƒë∆°n v√† thu·∫ø t·∫°i Vi·ªát Nam.
Context t·ª´ Rasa: Intent={intent}, Entities={entities}, Confidence={confidence}

D·ª±a tr√™n context n√†y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch chuy√™n nghi·ªáp v√† ch√≠nh x√°c.
N·∫øu li√™n quan ƒë·∫øn h√≥a ƒë∆°n, thu·∫ø VAT, k·∫ø to√°n - h√£y ƒë∆∞a ra th√¥ng tin chi ti·∫øt.
N·∫øu l√† c√¢u h·ªèi chung, h√£y tr·∫£ l·ªùi th√¢n thi·ªán v√† h·ªØu √≠ch.

Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát
Phong c√°ch: Chuy√™n nghi·ªáp, th√¢n thi·ªán, d·ªÖ hi·ªÉu
            """,
            
            'general_context': """
B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán cho h·ªá th·ªëng qu·∫£n l√Ω h√≥a ƒë∆°n.
Context t·ª´ Rasa: Intent={intent}, Entities={entities}, Confidence={confidence}

H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n context n√†y. N·∫øu Rasa ƒë√£ x√°c ƒë·ªãnh ƒë∆∞·ª£c intent/entities,
h√£y s·ª≠ d·ª•ng th√¥ng tin ƒë√≥ ƒë·ªÉ ƒë∆∞a ra ph·∫£n h·ªìi ph√π h·ª£p.

Kh·∫£ nƒÉng c·ªßa h·ªá th·ªëng:
- T·∫°o v√† qu·∫£n l√Ω m·∫´u h√≥a ƒë∆°n
- OCR tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ h√¨nh ·∫£nh
- T√¨m ki·∫øm v√† ph√¢n t√≠ch h√≥a ƒë∆°n
- T√≠nh to√°n thu·∫ø VAT
- H·ªó tr·ª£ upload file PDF/image

Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát
Phong c√°ch: Th√¢n thi·ªán, h·ªØu √≠ch
            """
        }
    
    async def process_message(self, message: str, user_id: str = 'default') -> Dict[str, Any]:
        """
        X·ª≠ l√Ω tin nh·∫Øn v·ªõi Rasa-first approach
        """
        try:
            # Step 1: G·ª≠i tin nh·∫Øn t·ªõi Rasa
            rasa_result = await self.query_rasa(message, user_id)
            
            # Step 2: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng response t·ª´ Rasa
            if self.is_good_rasa_response(rasa_result):
                # Rasa ƒë√£ cho response t·ªët
                response = self.format_rasa_response(rasa_result, message, user_id)
                logger.info(f"Using Rasa response for user {user_id}")
                
            else:
                # Fallback sang Hybrid System thay v√¨ OpenAI tr·ª±c ti·∫øp
                response = await self.fallback_to_hybrid_system(message, user_id, rasa_result)
                logger.info(f"Fallback to Hybrid System for user {user_id}")
            
            # Step 3: Update conversation history
            self.update_conversation_history(user_id, message, response)
            
            return response
            
        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            return {
                'message': 'Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i sau.',
                'type': 'text',
                'method': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    async def query_rasa(self, message: str, user_id: str) -> Dict[str, Any]:
        """
        G·ª≠i tin nh·∫Øn t·ªõi Rasa v√† l·∫•y response + intent/entities
        """
        try:
            # 1. G·ª≠i webhook request ƒë·ªÉ l·∫•y response
            webhook_payload = {
                "sender": user_id,
                "message": message
            }
            
            webhook_response = requests.post(
                f"{self.rasa_url}/webhooks/rest/webhook",
                json=webhook_payload,
                timeout=10
            )
            
            # 2. G·ª≠i parse request ƒë·ªÉ l·∫•y intent/entities
            parse_payload = {
                "text": message
            }
            
            parse_response = requests.post(
                f"{self.rasa_url}/model/parse",
                json=parse_payload,
                timeout=10
            )
            
            # 3. Combine results
            webhook_data = webhook_response.json() if webhook_response.status_code == 200 else []
            parse_data = parse_response.json() if parse_response.status_code == 200 else {}
            
            return {
                'responses': webhook_data,
                'intent': parse_data.get('intent', {}),
                'entities': parse_data.get('entities', []),
                'text': parse_data.get('text', message),
                'success': webhook_response.status_code == 200 and parse_response.status_code == 200
            }
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Rasa request failed: {str(e)}")
            return {
                'responses': [],
                'intent': {'name': 'unknown', 'confidence': 0.0},
                'entities': [],
                'text': message,
                'success': False,
                'error': str(e)
            }
    
    def is_good_rasa_response(self, rasa_result: Dict[str, Any]) -> bool:
        """
        Ki·ªÉm tra xem response t·ª´ Rasa c√≥ t·ªët kh√¥ng - Enhanced version
        """
        if not rasa_result.get('success', False):
            logger.debug("Rasa response failed - not successful")
            return False
        
        responses = rasa_result.get('responses', [])
        if not responses:
            logger.debug("Rasa response failed - no responses")
            return False
        
        # L·∫•y intent v√† confidence
        intent = rasa_result.get('intent', {})
        intent_name = intent.get('name', 'unknown')
        confidence = intent.get('confidence', 0.0)
        
        response_text = responses[0].get('text', '').lower().strip()
        
        logger.debug(f"Rasa response check: intent={intent_name}, confidence={confidence:.3f}, text='{response_text[:50]}...'")
        
        # 1. Ki·ªÉm tra confidence - Stricter
        if confidence < self.min_confidence:
            logger.debug(f"Rasa response rejected - confidence too low: {confidence:.3f} < {self.min_confidence}")
            return False
        
        # 2. Ki·ªÉm tra response length (qu√° ng·∫Øn c√≥ th·ªÉ l√† generic)
        if len(response_text) < 15:  # TƒÉng t·ª´ 10 ‚Üí 15
            logger.debug(f"Rasa response rejected - too short: {len(response_text)} chars")
            return False
        
        # 3. Ki·ªÉm tra bad patterns (Rasa th·ª´a nh·∫≠n kh√¥ng bi·∫øt)
        for bad_pattern in self.bad_response_patterns:
            if bad_pattern in response_text:
                logger.debug(f"Rasa response rejected - contains bad pattern: '{bad_pattern}'")
                return False
        
        # 4. Ki·ªÉm tra suspicious patterns (c√≥ th·ªÉ ƒëang "b·ªãa")
        suspicious_count = 0
        for suspicious_pattern in self.suspicious_patterns:
            if suspicious_pattern in response_text:
                suspicious_count += 1
        
        if suspicious_count >= 2:  # N·∫øu c√≥ 2+ suspicious patterns
            logger.debug(f"Rasa response suspicious - contains {suspicious_count} suspicious patterns")
            return False
        
        # 5. Ki·ªÉm tra generic patterns
        generic_count = 0
        for generic_pattern in self.generic_patterns:
            if generic_pattern in response_text:
                generic_count += 1
        
        if generic_count >= 1 and confidence < self.good_confidence:
            logger.debug(f"Rasa response rejected - generic response with low confidence")
            return False
        
        # 6. Ki·ªÉm tra intent relevance
        if self.is_intent_relevant_to_message(intent_name, rasa_result.get('text', '')):
            pass  # Intent ph√π h·ª£p
        else:
            logger.debug(f"Rasa response suspicious - intent '{intent_name}' may not be relevant")
            if confidence < self.good_confidence:
                return False
        
        # 7. Final confidence-based decision
        if confidence >= self.excellent_confidence:
            logger.debug(f"Rasa response excellent - high confidence: {confidence:.3f}")
            return True
        elif confidence >= self.good_confidence:
            logger.debug(f"Rasa response good - decent confidence: {confidence:.3f}")
            return True
        elif confidence >= self.min_confidence:
            # Medium confidence - need additional checks
            if len(response_text) > 30 and suspicious_count == 0:
                logger.debug(f"Rasa response acceptable - medium confidence but good content")
                return True
            else:
                logger.debug(f"Rasa response rejected - medium confidence with poor content")
                return False
        
        return False
    
    def is_intent_relevant_to_message(self, intent_name: str, original_message: str) -> bool:
        """
        Ki·ªÉm tra xem intent c√≥ ph√π h·ª£p v·ªõi message g·ªëc kh√¥ng
        """
        if intent_name == 'unknown' or not intent_name:
            return False
        
        original_lower = original_message.lower()
        
        # Intent relevance mapping
        relevance_keywords = {
            'greet': ['ch√†o', 'hello', 'hi', 'xin ch√†o'],
            'goodbye': ['t·∫°m bi·ªát', 'bye', 'goodbye', 'c·∫£m ∆°n'],
            'ask_invoice_help': ['h√≥a ƒë∆°n', 'invoice', 'bill', 'gi√∫p'],
            'create_invoice_template': ['t·∫°o', 'm·∫´u', 'template', 'create'],
            'extract_invoice_data': ['tr√≠ch xu·∫•t', 'extract', 'ƒë·ªçc', 'ph√¢n t√≠ch'],
            'search_invoice': ['t√¨m', 'search', 't√¨m ki·∫øm'],
            'upload_invoice': ['upload', 't·∫£i l√™n', 'g·ª≠i file'],
            'ask_template_types': ['lo·∫°i m·∫´u', 'template types', 'm·∫´u n√†o'],
            'request_ocr_help': ['ocr', 'nh·∫≠n d·∫°ng', 'ƒë·ªçc ch·ªØ']
        }
        
        # Ki·ªÉm tra keyword relevance
        if intent_name in relevance_keywords:
            keywords = relevance_keywords[intent_name]
            for keyword in keywords:
                if keyword in original_lower:
                    return True
            return False  # Intent c√≥ trong map nh∆∞ng kh√¥ng t√¨m th·∫•y keyword
        
        # Intent kh√¥ng trong map - assume relevant (cho c√°c custom intent)
        return True
    
    def format_rasa_response(self, rasa_result: Dict[str, Any], original_message: str, user_id: str) -> Dict[str, Any]:
        """
        Format response t·ª´ Rasa th√†nh format chu·∫©n
        """
        responses = rasa_result.get('responses', [])
        intent = rasa_result.get('intent', {})
        entities = rasa_result.get('entities', [])
        
        # L·∫•y response ch√≠nh t·ª´ Rasa
        main_response = responses[0].get('text', '') if responses else 'C·∫£m ∆°n b·∫°n ƒë√£ li√™n h·ªá!'
        
        # Enhance v·ªõi th√¥ng tin t·ª´ entities n·∫øu c√≥
        if entities:
            main_response = self.enhance_with_entities(main_response, entities)
        
        # T·∫°o suggestions d·ª±a tr√™n intent
        suggestions = self.get_intent_suggestions(intent.get('name', 'unknown'))
        
        return {
            'message': main_response,
            'type': 'text',
            'method': 'rasa',
            'intent': intent.get('name', 'unknown'),
            'confidence': intent.get('confidence', 0.0),
            'entities': entities,
            'suggestions': suggestions,
            'timestamp': datetime.now().isoformat(),
            'user_id': user_id,
            'original_message': original_message,
            'rasa_buttons': responses[0].get('buttons', []) if responses else [],
            'rasa_custom': responses[0].get('custom', {}) if responses else {}
        }
    
    async def fallback_to_hybrid_system(self, message: str, user_id: str, rasa_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Fallback sang Hybrid System khi Rasa kh√¥ng tr·∫£ l·ªùi ƒë∆∞·ª£c
        """
        try:
            # Import hybrid chat handler
            from handlers.hybrid_chat_handler import HybridChatBot
            
            logger.info(f"Falling back to Hybrid System for user {user_id}")
            
            # Kh·ªüi t·∫°o hybrid system
            hybrid_chat = HybridChatBot()
            
            # S·ª≠ d·ª•ng hybrid system ƒë·ªÉ x·ª≠ l√Ω tin nh·∫Øn
            hybrid_response = await hybrid_chat.process_message(message, user_id)
            
            # Enhance response v·ªõi info v·ªÅ fallback
            if isinstance(hybrid_response, dict):
                hybrid_response['method'] = f"hybrid_fallback_{hybrid_response.get('method', 'unknown')}"
                hybrid_response['fallback_reason'] = "rasa_poor_response"
                hybrid_response['rasa_context'] = rasa_result
                
                return hybrid_response
            else:
                # Fallback to OpenAI n·∫øu hybrid c≈©ng fail
                return await self.fallback_to_openai(message, user_id, rasa_result)
                
        except Exception as e:
            logger.error(f"Hybrid system fallback failed: {str(e)}")
            # Ultimate fallback to OpenAI
            return await self.fallback_to_openai(message, user_id, rasa_result)
    
    async def fallback_to_openai(self, message: str, user_id: str, rasa_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Fallback sang OpenAI v·ªõi context t·ª´ Rasa (ultimate fallback)
        """
        try:
            intent = rasa_result.get('intent', {})
            entities = rasa_result.get('entities', [])
            intent_name = intent.get('name', 'unknown')
            confidence = intent.get('confidence', 0.0)
            
            # Ch·ªçn system prompt ph√π h·ª£p
            if any(keyword in intent_name.lower() for keyword in ['invoice', 'template', 'ocr', 'tax']):
                system_prompt = self.system_prompts['invoice_context']
            else:
                system_prompt = self.system_prompts['general_context']
            
            # Format system prompt v·ªõi context
            formatted_prompt = system_prompt.format(
                intent=intent_name,
                entities=entities,
                confidence=confidence
            )
            
            # L·∫•y conversation history
            history = self.get_conversation_history(user_id)
            
            # G·ªçi OpenAI API
            messages = [{"role": "system", "content": formatted_prompt}]
            messages.extend(history)
            messages.append({"role": "user", "content": message})
            
            response = self.ai_model.client.chat.completions.create(
                model=self.ai_model.model,
                messages=messages,
                max_tokens=self.ai_model.max_tokens,
                temperature=self.ai_model.temperature
            )
            
            ai_response = response.choices[0].message.content.strip()
            
            # T·∫°o suggestions
            suggestions = self.get_intent_suggestions(intent_name)
            
            return {
                'message': ai_response,
                'type': 'text',
                'method': 'openai_ultimate_fallback',
                'intent': intent_name,
                'confidence': confidence,
                'entities': entities,
                'suggestions': suggestions,
                'timestamp': datetime.now().isoformat(),
                'user_id': user_id,
                'original_message': message,
                'rasa_context': rasa_result,
                'fallback_reason': 'hybrid_system_failed'
            }
            
        except Exception as e:
            logger.error(f"Ultimate OpenAI fallback failed: {str(e)}")
            
            # Final simple response
            return {
                'message': f'C·∫£m ∆°n b·∫°n ƒë√£ h·ªèi: "{message}". T√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c li√™n h·ªá h·ªó tr·ª£.',
                'type': 'text',
                'method': 'simple_fallback',
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'suggestions': ['Th·ª≠ l·∫°i', 'H·ªó tr·ª£ k·ªπ thu·∫≠t', 'Li√™n h·ªá admin']
            }
    
    def enhance_with_entities(self, response: str, entities: List[Dict]) -> str:
        """
        Enhance response v·ªõi th√¥ng tin t·ª´ entities
        """
        if not entities:
            return response
        
        # Extract useful entity info
        entity_info = []
        for entity in entities:
            entity_value = entity.get('value', '')
            entity_type = entity.get('entity', '')
            
            if entity_value and entity_type:
                entity_info.append(f"{entity_type}: {entity_value}")
        
        if entity_info:
            enhancement = f"\n\nüìã Th√¥ng tin nh·∫≠n d·∫°ng: {', '.join(entity_info)}"
            return response + enhancement
        
        return response
    
    def get_intent_suggestions(self, intent_name: str) -> List[str]:
        """
        T·∫°o suggestions d·ª±a tr√™n intent
        """
        suggestion_map = {
            'greet': ['T√¥i c·∫ßn gi√∫p ƒë·ª° v·ªÅ h√≥a ƒë∆°n', 'T·∫°o m·∫´u h√≥a ƒë∆°n', 'Upload file OCR'],
            'ask_invoice_help': ['T·∫°o h√≥a ƒë∆°n m·ªõi', 'Xem m·∫´u c√≥ s·∫µn', 'H∆∞·ªõng d·∫´n OCR'],
            'create_invoice_template': ['Ch·ªçn lo·∫°i m·∫´u', 'Th√™m field t√πy ch·ªânh', 'Xem preview m·∫´u'],
            'extract_invoice_data': ['Upload file PDF', 'Upload h√¨nh ·∫£nh', 'Xem k·∫øt qu·∫£ OCR'],
            'search_invoice': ['T√¨m theo MST', 'T√¨m theo ng√†y', 'T√¨m theo s·ªë ti·ªÅn'],
            'ask_template_types': ['M·∫´u h√≥a ƒë∆°n VAT', 'M·∫´u h√≥a ƒë∆°n d·ªãch v·ª•', 'M·∫´u h√≥a ƒë∆°n h√†ng h√≥a'],
            'goodbye': ['C·∫£m ∆°n b·∫°n!', 'H·∫πn g·∫∑p l·∫°i!'],
            'unknown': ['H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng', 'C√°c t√≠nh nƒÉng c√≥ s·∫µn', 'H·ªó tr·ª£ k·ªπ thu·∫≠t', 'FAQ']
        }
        
        return suggestion_map.get(intent_name, ['T·∫°o h√≥a ƒë∆°n', 'OCR file', 'T√¨m ki·∫øm', 'H·ªó tr·ª£'])
    
    def update_conversation_history(self, user_id: str, message: str, response: Dict[str, Any]):
        """
        C·∫≠p nh·∫≠t l·ªãch s·ª≠ conversation
        """
        if user_id not in self.conversation_history:
            self.conversation_history[user_id] = []
        
        # Add user message
        self.conversation_history[user_id].append({
            "role": "user",
            "content": message
        })
        
        # Add bot response
        self.conversation_history[user_id].append({
            "role": "assistant", 
            "content": response.get('message', '')
        })
        
        # Keep only last 10 messages (5 turns)
        if len(self.conversation_history[user_id]) > 10:
            self.conversation_history[user_id] = self.conversation_history[user_id][-10:]
    
    def get_conversation_history(self, user_id: str) -> List[Dict[str, str]]:
        """
        L·∫•y l·ªãch s·ª≠ conversation
        """
        return self.conversation_history.get(user_id, [])[-6:]  # Last 3 turns